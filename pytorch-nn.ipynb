{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weights * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 1]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 1]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                                requires_grad=True,\n",
    "                                                dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                            requires_grad=True,\n",
    "                                            dtype=torch.float))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds\n",
    "\n",
    "# OR with torch.no_grad():\n",
    "#     y_preds = model_0(X_test)\n",
    "\n",
    "# y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch training loop:\n",
    "\n",
    "For the training loop, we'll build the following steps:\n",
    "\n",
    "Number\tStep name\tWhat does it do?\tCode example\n",
    "\n",
    "1\tForward pass\tThe model goes through all of the training data once, performing its forward() function calculations.\t\n",
    "\n",
    "model(x_train)\n",
    "\n",
    "2\tCalculate the loss\tThe model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.\t\n",
    "\n",
    "loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "3\tZero gradients\tThe optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step.\t\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "4\tPerform backpropagation on the loss\tComputes the gradient of the loss with respect for every model parameter to be updated (each parameter with requires_grad=True). This is known as backpropagation, hence \"backwards\".\t\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "5\tUpdate the optimizer (gradient descent)\tUpdate the parameters with requires_grad=True with respect to the loss gradients in order to improve them.\t\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.48106518387794495\n",
      "Epoch: 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss: 0.3463551998138428\n",
      "Epoch: 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss: 0.21729660034179688\n",
      "Epoch: 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss: 0.14464017748832703\n",
      "Epoch: 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss: 0.11360953003168106\n",
      "Epoch: 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss: 0.09919948130846024\n",
      "Epoch: 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss: 0.08886633068323135\n",
      "Epoch: 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss: 0.0805937647819519\n",
      "Epoch: 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss: 0.07232122868299484\n",
      "Epoch: 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss: 0.06473556160926819\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_0.train()\n",
    "    \n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f'Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.7, bias: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Find our model's learned parameters\n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "print(model_0.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weights}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8141],\n",
       "        [0.8256],\n",
       "        [0.8372],\n",
       "        [0.8488],\n",
       "        [0.8603],\n",
       "        [0.8719],\n",
       "        [0.8835],\n",
       "        [0.8950],\n",
       "        [0.9066],\n",
       "        [0.9182]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.eval()\n",
    "\n",
    "# 2. Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  # in our case, we haven't setup device-agnostic code yet so our data and model are\n",
    "  # on the CPU by default.\n",
    "  # model_0.to(device)\n",
    "  # X_test = X_test.to(device)\n",
    "  y_preds = model_0(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "             ('linear_layer.bias', tensor([0.8300]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        return self.linear_layer(x)\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model_1 = LinearRegressionModelV2()\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), # optimize newly created model's parameters\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.5551779866218567 | Test loss: 0.5739762187004089\n",
      "Epoch: 10 | Train loss: 0.4399680495262146 | Test loss: 0.4392663538455963\n",
      "Epoch: 20 | Train loss: 0.3247582018375397 | Test loss: 0.30455657839775085\n",
      "Epoch: 30 | Train loss: 0.20954827964305878 | Test loss: 0.16984674334526062\n",
      "Epoch: 40 | Train loss: 0.09433844685554504 | Test loss: 0.03513689711689949\n",
      "Epoch: 50 | Train loss: 0.023886386305093765 | Test loss: 0.04784906655550003\n",
      "Epoch: 60 | Train loss: 0.0199567973613739 | Test loss: 0.04580312222242355\n",
      "Epoch: 70 | Train loss: 0.016517987474799156 | Test loss: 0.0375305712223053\n",
      "Epoch: 80 | Train loss: 0.013089170679450035 | Test loss: 0.029944902285933495\n",
      "Epoch: 90 | Train loss: 0.009653178043663502 | Test loss: 0.02167237363755703\n",
      "Epoch: 100 | Train loss: 0.006215679459273815 | Test loss: 0.014086711220443249\n",
      "Epoch: 110 | Train loss: 0.002787243574857712 | Test loss: 0.005814164876937866\n",
      "Epoch: 120 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 130 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 140 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 150 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 160 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 170 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 180 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n",
      "Epoch: 190 | Train loss: 0.0012645035749301314 | Test loss: 0.013801807537674904\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "\n",
    "    y_pred = model_1(X_train)\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_1.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('linear_layer.weight', tensor([[0.6968]])),\n",
      "             ('linear_layer.bias', tensor([0.3025]))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.7, bias: 0.3\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html \n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "pprint(model_1.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weights}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8600],\n",
       "        [0.8739],\n",
       "        [0.8878],\n",
       "        [0.9018],\n",
       "        [0.9157],\n",
       "        [0.9296],\n",
       "        [0.9436],\n",
       "        [0.9575],\n",
       "        [0.9714],\n",
       "        [0.9854]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_1(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
